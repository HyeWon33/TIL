2장 : 6

3장 :  6 7



- 평균 제곱근 편차 root mean square deciation RMSD, 평균 제곱근 오차 root mean square error RMSE
  - 추정 값 또는 모델이 예측한 값과 실제 환견에서 관찰되는 값의 차이를 다룰 때 흔히 사용하는 측도.
  - 정밀도(precision)를 표현하는데 적합.

https://scribblinganything.tistory.com/265





## 2.6 모델 선택과 훈련

### 2.6.1 훈련 세트에서 훈련하고 평가하기

- 선형 회귀 모델 훈련

  - ```python
    from sklearn.linear_model import LinearRegression
    
    lin_reg = LinearRegression()
    lin_reg.fit(housing_prepared, housing_labels)
    ```

    - ```
      LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
      ```

- 훈련 세트에 있는 몇 개 샘플에 전체 파이프라인을 적용

  - ``` python
    some_data = housing.iloc[:5]
    some_labels = housing_labels.iloc[:5]
    some_data_prepared = full_pipeline.transform(some_data)
    print("예측 : ", lin_reg.predict(some_data_prepared))
    
    #some_data(5개)를 full pipelie의 transform 메소드로 데이터 변환 해서 some_data_prepared만든다.
    ```
    
    - ```
      예측: [ 85657.90192014 305492.60737488 152056.46122456 186095.70946094 244550.67966089]
      ```
    
  - ```
    print("레이블:", list(some_labels))
    ```

    - ```
      레이블: [72100.0, 279600.0, 82700.0, 112500.0, 238300.0]
      ```

- mean_square_error 함수를 사용해 전체 훈련 세트에 대한 회귀 모델의 RMSE를 측정

  - ```python
    from sklearn.metrics import mean_squared_error
    
    housing_predictions = lin_reg.predict(housing_prepared)
    lin_mse = mean_squared_error(housing_labels, housing_predictions)
    lin_rmse = np.sqrt(lin_mse)
    lin_rmse
    ```

    - ```
      68627.87390018745
      ```

    - 예측 오차가 만족스럽지 않다. 모델이 훈련 데이터에 과소적합된 사례이다.
    
  - score method

    - ```
      lin_reg.score(housing_prepared, housing_labels)
      ```

    - 결과가 1에 가까울수록 좋고 0이 되면 평균 정도 예측

- DecisionTreeRegressor (결정 트리)

  - 이 모델은 강력하고 데이터에서 복잡한 비선형 관계를 찾을 수 있다. (6장에서 자세히)

  - 모델 훈련
  
    - ```python
      from sklearn.tree import DecisionTreeRegressor
      
      tree_reg = DecisionTreeRegressor(random_state=42)
      tree_reg.fit(housing_prepared, housing_labels)
      ```
  
  - 훈련 세트 평가
  
    - ```
      housing_predictions = tree_reg.predict(housing_prepared)
      tree_mse = mean_squared_error(housing_labels, housing_predictions)
      tree_rmse = np.sqrt(tree_mse)
      tree_rmse
      ```

      - ```
        0.0
        ```
  
      - -> 완벽하게 타겟값 맞췄다. -> 훈련 세트에 너무 적합하게 훈련되었다. -> 과대적합

  - ```
    tree_reg.score(housing_prepared, housing_labels)
    ```

    - ```
      1.0
      ```
  
  - housing_prepared 만들 때 훈련 세트 한번 떼어내는데 한번 더 떼어내는 것. 한번 더 떼어내서 수행하는 것을 검증 세트라고 한다. 검증 세트 가지고 모델을 평가할 수 있다.
  
  - 더 좋은 방법은 cross_val_score : 교차 검증



### 2.6.2 교차 검증을 사용한 평가

- 사이킷런의 k-겹 교차 검증(k-fold cross-validation)

  - 예를 들어 3겹이면 첫 번째 : 검증 세트, 나머지 : 모델 훈련. 첫 번때 에서 모델 검증 이렇게 두 번째를 검증 세트로 한번 세 번째를 검증 세트로 한번 이렇게 3번 나온 검증세트의 평균을 내서 최종 검증 점수를 만든다.

  - ```python
    from sklearn.model_selection import cross_val_score
    
    scores = cross_val_score(tree_reg, housing_prepared, housing_labels,
                             scoring="neg_mean_squared_error", cv=10)
    tree_rmse_scores = np.sqrt(-scores)
    
    #tree_reg : 개체
    #housing_prepared : 훈련 세트
    #housing_data : 타겟 data
    #negative_mean_squared_error : 사이킷런은 점수 높은 것이 좋다고 가정한다. 하지만 평균 제곱은 반대로 높은 값이 좋은 값이 아니다. 그래서 음수로 만들어서 평가할 때 사용한다.
    #cv : fold. 덩어리.
    #사이킷런의 교차 검증 기능은 scoring 매개변수에 (낮을수로 좋은) 비용 함수가 아니라 (클수록 좋은)효용 함수를 기대한다. 그래서 평균 제곱 오차(MSE)의 반댓값(즉, 음숫값)을 계산하는 neg_mean_squared_error 함수를 사용한다. 이런 이유로 제곱근을 계산하기 전에 -score로 부호를 바바꿨다.
    ```

  - 결과
    
    - ```python
      def display_scores(scores):
          print("점수:", scores)
          print("평균:", scores.mean())
          print("표준 편차:", scores.std())
      
      display_scores(tree_rmse_scores)
      ```
    
      - ```
        점수: [72831.45749112 69973.18438322 69528.56551415 72517.78229792
         69145.50006909 79094.74123727 68960.045444   73344.50225684
         69826.02473916 71077.09753998]
        평균: 71629.89009727491
        표준 편차: 2914.035468468928
        ```
    
      - 결정 트리 결과가 좋아 보이지 않는다.  실제로 선형 회귀 모델보다 나쁘다.
    
      - 교차 검증으로 모델의 성능을 추정하는 것뿐만 아니라 이 추정이 얼마나 정확한지(즉, 표준편차) 측정할 수 있다.
    
      - 결정 트리 점수 : 대략 평균 71,407 +- 2,439 사이
    
      - 모델을 여러 번 훈련시켜야 해서 비용이 비싸므로 교차 검증이 언제나 쓸 수 있는 것은 아니다.
    
  - 선형 회귀 모델의 점수
  
    - ```python
      lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,
                                   scoring="neg_mean_squared_error", cv=10)
      lin_rmse_scores = np.sqrt(-lin_scores)
      display_scores(lin_rmse_scores)
      ```
  
      - ```
        점수: [71762.76364394 64114.99166359 67771.17124356 68635.19072082
         66846.14089488 72528.03725385 73997.08050233 68802.33629334
         66443.28836884 70139.79923956]
        평균: 69104.07998247063
        표준 편차: 2880.3282098180644
        ```

  - RandomForestRegressor (7장에서 자세히)

    - 랜덤 포레스트는 특성을 무작위로 선택해서 많은 결정 트리를 만들고 그 예측을 평균 내는 방식으로 작동한다.

    - 여러 다른 모델을 모아서 하나의 모델을 만드는 것을 앙상블 학습이라고 하며 머신러닝 알고리즘의 성능을 극대화하는 방법 중 하나이다.
  
    - ```python
      from sklearn.ensemble import RandomForestRegressor
      
      forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)
      forest_reg.fit(housing_prepared, housing_labels)
      
      housing_predictions = forest_reg.predict(housing_prepared)
      forest_mse = mean_squared_error(housing_labels, housing_predictions)
      forest_rmse = np.sqrt(forest_mse)
      forest_rmse
      ```
  
      - ```
        18650.698705770003
        ```
  
    - ```python
      from sklearn.model_selection import cross_val_score
      
      forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,
                                      scoring="neg_mean_squared_error", cv=10)
      forest_rmse_scores = np.sqrt(-forest_scores)
      display_scores(forest_rmse_scores)
      ```
  
      - ```
        점수: [51559.63379638 48737.57100062 47210.51269766 51875.21247297
         47577.50470123 51863.27467888 52746.34645573 50065.1762751
         48664.66818196 54055.90894609]
        평균: 50435.58092066179
        표준 편차: 2203.3381412764606
        ```
  
      - 훈련 세트에 대한 점수가 검증 세트에 대한 점수보다 훨씬 낮으므로 이 모델도 여전히 과대적합되어 있다.
      - 과대적합을 해결하는 방법은 모델을 간단히 하거나, 제한 하거나(규제), 더 많은 훈련 데이터를 모으는 것이다.





## 3.6 다중 레이블 분류 multilabel classification

- 출력하는 output이 하나가 아니라 여러개인 경우 하나의 샘플에서 레이블이 여러개 출력하는 시스템

- ```python
  from sklearn.neighbors import KNeighborsClassifier
  
  y_train_large = (y_train >= 7) #타겟값이 7이상
  y_train_odd = (y_train % 2 == 1) #타겟값이 홀수
  y_multilable = np.c_[y_train_large, y_train_odd] #타겟값이 2개 된거다. np.c : 합친다(열 방향).
  
  knn_clf = KNeighborsClassifier()
  knn_clf.fit(X_train, y_multilabel)
  ```

- ```python
  knn_clf.predict([some_digit]) #false / true 2개의 레이블 나온다. some_digit : 5
  ```

  - ```python
    array([[False, True]]) #숫자 5는 크지 않고(y_train_large : False) 홀수(y_train_odd : True)이다.
    ```

- 다중 레이블 분류기를 평가하는 방법

  - 각 레이블의 F1 점수를 구하고(또는 앞서 언급한 어떤 이진 분류 지표를 사용하여) 간단하게 평균 점수를 계산한다.

  - 모든 레이블에 대한 F1 점수의 평균을 계산하는 코드

    - ```python
      y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilable, cv=3)
      f1_score(y_multilabel, y_train_knn_pred, average="macro")
      
      #macro[매크로] : 레이블 별로 따로 f1 score 계산해서 평균.
      #micro : 모든 레이블 별로 fn, fp, tp를 다 더해서 f1 score 최종적으로 계산.
      ```

      - ```
        0.976410265560605
        ```

      - 이 코드는 모든 레이블의 가중치가 같다고 가정

      - 레이블에 클래스의 지지도(support) (즉, 타겟 레이블에 속한 샘플 수)를 가중치로 두려면 average="weighted" (macro랑 같지만 샘플 수로 가중)




## 3.7 다중 출력 분류 multioutput classification

- 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화한 것이다(즉, 값을 두 개 이상 가질 수 있다).

- 잡음 제거 시스템

  - 숫자 이미지를 입력을 받고 깨끗한 숫자 이미지를 MNIST 이미지처럼 픽셀의 강도를 담은 배열로 출력

  - 분류기의 출력이 다중 레이블(픽셀당 한 레이블)이고 각 레이블은 값을 여러개 가진다(0~255까지의 픽셀 강도).

  - MNIST 이미지에서 추출한 훈련 세트와 테스트 세트에 넘파이 randint()함수를 사용하여 픽셀 강도에 잡음을 추가

    - ```python
      noise = np.random.randint(0, 100, (len(X_train), 784))
      X_train_mod = X_train + noise #noise 섞었다.
      noise = np.random.randint(0, 100, (len(X_test), 784))
      X_test_mod = X_test + noise
      y_train_mod = X_train #레이블이 훈련 세트 자기 자신이 된다.
      y_test_mod = X_test
      
      #y_train_mod같은 경우 784개 레이블 나온다. -> 하나의 레이블에 0~255까지 픽셀 값 : 다중 레이블 -> 한 레이블에서 여러 가지 출력 : 다중 출력 분류 예제
      ```

  - 분류기를 훈련시켜 이미지를 깨끗하게 만들기
  
    - ```python
      some_index = 0
      plt.subplot(121); plot_digit(X_test_mod[some_index])
      plt.subplot(122); plot_digit(y_test_mod[some_index])
      save_fig("noisy_digit_example_plot")
      plt.show()
      
      knn_clf.fit(X_train_mod, y_train_mod)
      clean_digit = knn_clf.predict([X_test_mod[some_index]])
      plot_digit(clean_digit)
      save_fig("cleaned_digit_example_plot")
      ```
      
    - 최근접 이웃에 의해 가까이 있는 이웃에 타겟값에 픽셀 계산.











