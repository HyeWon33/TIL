## 6.8 회귀

- DecisionTreeRegressor를 사용해 잡음이 섞인 2차원 함수 형태의 데이터셋에서 max_depth=2 설정하여 회귀트리 만들어 보기

- ```python
  # 2차식으로 만든 데이터셋 + 잡음
  np.random.seed(42)
  m = 200
  X = np.random.rand(m, 1) #회귀는 타겟 클래스를 2차원 평면에 표현해야 하니까 특성 1개 사용.
  y = 4 * (X - 0.5) ** 2 #2차식
  y = y + np.random.randn(m, 1) / 10
  ```

- ```python
  from sklearn.tree import DecisionTreeRegressor
  
  tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)
  tree_reg.fit(X, y)
  ```

- ```python
  export_graphviz(
          tree_reg1,
          out_file=os.path.join(IMAGES_PATH, "regression_tree.dot"),
          feature_names=["x1"],
          rounded=True,
          filled=True
      )
  
  Source.from_file(os.path.join(IMAGES_PATH, "regression_tree.dot"))
  ```

- - ![그림6-4](https://user-images.githubusercontent.com/52944554/160781976-ef3da915-a991-42ff-9306-aa1882b02b4c.PNG)
    - 분류 트리와의 차이점은 각 노드에서 클래스를 예측하는 대신 어떤 값을 예측한다.
      - 예) x1=0.6 -> value=0.111 리프 노드에 도달
        - 이 리프 노드에 있는 110개 훈련 샘플의 평균 타깃값이 예측값이 된다. 이 예측값을 사용해 110개 샘플에 대한 평균제곱오차(MSE)를 계산하면 0.015
  - ![그림6-5](https://user-images.githubusercontent.com/52944554/160782053-c791a65e-4472-418d-b140-f284bcd08c57.PNG)
    - 두 개의 결정 트리 회귀 모델의 예측
  
- CART알고리즘

  - 훈련 세트를 불순도를 최소화하는 방향으로 분할하는 대신 평균제곱오차를 최소화하도록 분할하는 것을 제외하고는 앞서 설명한 것과 거의 비슷하게 작동한다.
  - 규제하지 않으면  분류에서와 같이 회귀 작업에서도 결정 트리가 과대적합되기 쉽다.
  - ![그림6-6](https://user-images.githubusercontent.com/52944554/160782137-065e3cf1-1a78-4ed5-ac9f-4e59e7b3ee45.PNG)





## 6.9 불안정성

- 결정 트리는 계단 모양의 결정 경계를 만든다.
  - 모든 분할은 축에 수직이다. 그래서 훈련 세트의 회전에 민감하다.
  - 좋은 방향으로 회전시키는 PCA기법은 8장에서 계속...
- 훈련 데이터에 있는 작은 변화에도 매우 민감하다.
- 사이킷런에서 사용하는 훈련 알고리즘은 확률적이다. (random_state 지정하지 않으면)
  - 같은 훈련 데이터에서도 다른 모델을 얻게 될 수 있다.
- 이런 불안정성 다음장에서 극복...